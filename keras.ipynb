{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f1211801461b56e6d12a564045942443e109fed4"
   },
   "source": [
    "This notebook contains a generator class for Keras called `BSONIterator` that can read directly from the BSON data. You can use it in combination with `ImageDataGenerator` for doing data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "4036f11e-5223-46e5-8948-5cbf70a9bf73",
    "_uuid": "3767d2738682e30c292a466f66bc75fcc80a5076",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md\n",
      "Tensorflow-py3.ipynb\n",
      "categories.csv\n",
      "category_names.csv\n",
      "keras.ipynb\n",
      "most_freq_submission.csv.gz\n",
      "sample_submission.csv\n",
      "test.bson\n",
      "test_images.csv\n",
      "test_offsets.csv\n",
      "train.bson\n",
      "train_example.bson\n",
      "train_images.csv\n",
      "train_offsets.csv\n",
      "val_images.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os, sys, math, io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "import bson\n",
    "import struct\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "import tensorflow as tf\n",
    "\n",
    "from collections import defaultdict\n",
    "from tqdm import *\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \".\"]).decode(\"utf8\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "e87d27c475174e95fc69ab2014e53d897b50d7f1",
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2.0.8', '1.1.0')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__, tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "73a48b2662bb6595cf7f6a039523d5762f16e4e8",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = \".\"\n",
    "\n",
    "train_bson_path = os.path.join(data_dir, \"train.bson\")\n",
    "num_train_products = 7069896\n",
    "\n",
    "# train_bson_path = os.path.join(data_dir, \"train_example.bson\")\n",
    "# num_train_products = 82\n",
    "\n",
    "test_bson_path = os.path.join(data_dir, \"test.bson\")\n",
    "num_test_products = 1768172"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7446da8d28ee3336988887dc0de4bfc0a3c2e6e8"
   },
   "source": [
    "# Create lookup tables for BSON files\n",
    "\n",
    "The generator uses several lookup tables that describe the layout of the BSON file, which products and images are part of the training/validation sets, and so on.\n",
    "\n",
    "You only need to generate these tables once, as they get saved to CSV files. If you already have these CSV files, skip to part 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f27344b992bc0a156cbef189440c5e7bf4102e19"
   },
   "source": [
    "## Lookup table for categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "c1d1ce6a90fdbe859816a8a3c40a03923e5fc3c1",
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_level1</th>\n",
       "      <th>category_level2</th>\n",
       "      <th>category_level3</th>\n",
       "      <th>category_idx</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000021794</th>\n",
       "      <td>ABONNEMENT / SERVICES</td>\n",
       "      <td>CARTE PREPAYEE</td>\n",
       "      <td>CARTE PREPAYEE MULTIMEDIA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000012764</th>\n",
       "      <td>AMENAGEMENT URBAIN - VOIRIE</td>\n",
       "      <td>AMENAGEMENT URBAIN</td>\n",
       "      <td>ABRI FUMEUR</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000012776</th>\n",
       "      <td>AMENAGEMENT URBAIN - VOIRIE</td>\n",
       "      <td>AMENAGEMENT URBAIN</td>\n",
       "      <td>ABRI VELO - ABRI MOTO</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000012768</th>\n",
       "      <td>AMENAGEMENT URBAIN - VOIRIE</td>\n",
       "      <td>AMENAGEMENT URBAIN</td>\n",
       "      <td>FONTAINE A EAU</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000012755</th>\n",
       "      <td>AMENAGEMENT URBAIN - VOIRIE</td>\n",
       "      <td>SIGNALETIQUE</td>\n",
       "      <td>PANNEAU D'INFORMATION EXTERIEUR</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         category_level1     category_level2  \\\n",
       "category_id                                                    \n",
       "1000021794         ABONNEMENT / SERVICES      CARTE PREPAYEE   \n",
       "1000012764   AMENAGEMENT URBAIN - VOIRIE  AMENAGEMENT URBAIN   \n",
       "1000012776   AMENAGEMENT URBAIN - VOIRIE  AMENAGEMENT URBAIN   \n",
       "1000012768   AMENAGEMENT URBAIN - VOIRIE  AMENAGEMENT URBAIN   \n",
       "1000012755   AMENAGEMENT URBAIN - VOIRIE        SIGNALETIQUE   \n",
       "\n",
       "                             category_level3  category_idx  \n",
       "category_id                                                 \n",
       "1000021794         CARTE PREPAYEE MULTIMEDIA             0  \n",
       "1000012764                       ABRI FUMEUR             1  \n",
       "1000012776             ABRI VELO - ABRI MOTO             2  \n",
       "1000012768                    FONTAINE A EAU             3  \n",
       "1000012755   PANNEAU D'INFORMATION EXTERIEUR             4  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories_path = os.path.join(data_dir, \"category_names.csv\")\n",
    "categories_df = pd.read_csv(categories_path, index_col=\"category_id\")\n",
    "\n",
    "# Maps the category_id to an integer index. This is what we'll use to\n",
    "# one-hot encode the labels.\n",
    "categories_df[\"category_idx\"] = pd.Series(range(len(categories_df)), index=categories_df.index)\n",
    "\n",
    "categories_df.to_csv(\"categories.csv\")\n",
    "categories_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a84b57cf2bb7f281bc0de4e3118b4eef44ff195c"
   },
   "source": [
    "Create dictionaries for quick lookup of `category_id` to `category_idx` mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "c4d0fe4179a51c6772248ec350f1a648ace543eb",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_category_tables():\n",
    "    cat2idx = {}\n",
    "    idx2cat = {}\n",
    "    for ir in categories_df.itertuples():\n",
    "        category_id = ir[0]\n",
    "        category_idx = ir[4]\n",
    "        cat2idx[category_id] = category_idx\n",
    "        idx2cat[category_idx] = category_id\n",
    "    return cat2idx, idx2cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "a2160c7b1f95e9d7fe82ad7e735a26bebab58313",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat2idx, idx2cat = make_category_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "d4b1cf3b271baded43116c963e220653e6be5c3e",
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1000012755)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test if it works:\n",
    "cat2idx[1000012755], idx2cat[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "81e44d4969fd1a77426ccfd7def81fba6c32ee7c"
   },
   "source": [
    "## Read the BSON files\n",
    "\n",
    "We store the offsets and lengths of all items, allowing us random access to the items later.\n",
    "\n",
    "Inspired by code from: https://www.kaggle.com/vfdev5/random-item-access\n",
    "\n",
    "Note: this takes a few minutes to execute, but we only have to do it once (we'll save the table to a CSV file afterwards)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "02139d349bc2982e6d639abf21a60a16a956f80c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_bson(bson_path, num_records, with_categories):\n",
    "    rows = {}\n",
    "    with open(bson_path, \"rb\") as f, tqdm(total=num_records) as pbar:\n",
    "        offset = 0\n",
    "        while True:\n",
    "            item_length_bytes = f.read(4)\n",
    "            if len(item_length_bytes) == 0:\n",
    "                break\n",
    "\n",
    "            length = struct.unpack(\"<i\", item_length_bytes)[0]\n",
    "\n",
    "            f.seek(offset)\n",
    "            item_data = f.read(length)\n",
    "            assert len(item_data) == length\n",
    "\n",
    "            item = bson.BSON.decode(item_data)\n",
    "            product_id = item[\"_id\"]\n",
    "            num_imgs = len(item[\"imgs\"])\n",
    "\n",
    "            row = [num_imgs, offset, length]\n",
    "            if with_categories:\n",
    "                row += [item[\"category_id\"]]\n",
    "            rows[product_id] = row\n",
    "\n",
    "            offset += length\n",
    "            f.seek(offset)\n",
    "            pbar.update()\n",
    "\n",
    "    columns = [\"num_imgs\", \"offset\", \"length\"]\n",
    "    if with_categories:\n",
    "        columns += [\"category_id\"]\n",
    "\n",
    "    df = pd.DataFrame.from_dict(rows, orient=\"index\")\n",
    "    df.index.name = \"product_id\"\n",
    "    df.columns = columns\n",
    "    df.sort_index(inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "6749c16067a0c07c160e016c19b047324251f217",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7069896/7069896 [02:31<00:00, 46817.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 34s, sys: 41.7 s, total: 2min 15s\n",
      "Wall time: 2min 41s\n"
     ]
    }
   ],
   "source": [
    "%time train_offsets_df = read_bson(train_bson_path, num_records=num_train_products, with_categories=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "eb35d33d0d263c8a823584ab5be017f38a593c03",
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>offset</th>\n",
       "      <th>length</th>\n",
       "      <th>category_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6979</td>\n",
       "      <td>1000010653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6979</td>\n",
       "      <td>7318</td>\n",
       "      <td>1000010653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>14297</td>\n",
       "      <td>5455</td>\n",
       "      <td>1000004079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>19752</td>\n",
       "      <td>4580</td>\n",
       "      <td>1000004141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>24332</td>\n",
       "      <td>6346</td>\n",
       "      <td>1000015539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            num_imgs  offset  length  category_id\n",
       "product_id                                       \n",
       "0                  1       0    6979   1000010653\n",
       "1                  1    6979    7318   1000010653\n",
       "2                  1   14297    5455   1000004079\n",
       "3                  1   19752    4580   1000004141\n",
       "4                  1   24332    6346   1000015539"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_offsets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "dea0f658169db1546a269a51ab383d479a9971d1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_offsets_df.to_csv(\"train_offsets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "0411359ca44a61bbc03528559248734073578865",
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7069896"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many products?\n",
    "len(train_offsets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "643c0caab168896897920c01ce7c412ddcc6252c",
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5270"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many categories?\n",
    "len(train_offsets_df[\"category_id\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "bb1057ba7ea22b3710a9e7dc45d662c1fb13695e",
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12371293"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many images in total?\n",
    "train_offsets_df[\"num_imgs\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8a14c10ec8a4f490ad9618ad8b6faf67d430bd34"
   },
   "source": [
    "Also create a table for the offsets from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "1e0ab29b36a2fefeea7453a4baa57da95fc1f06c",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1768182it [00:36, 49067.08it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22 s, sys: 9.68 s, total: 31.7 s\n",
      "Wall time: 38.3 s\n"
     ]
    }
   ],
   "source": [
    "%time test_offsets_df = read_bson(test_bson_path, num_records=num_test_products, with_categories=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "7fc861302a5ece76e0f02dfabfe4251edc073be5",
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>offset</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>15826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>15826</td>\n",
       "      <td>5589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>21415</td>\n",
       "      <td>7544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>28959</td>\n",
       "      <td>4855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>33814</td>\n",
       "      <td>2921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            num_imgs  offset  length\n",
       "product_id                          \n",
       "10                 3       0   15826\n",
       "14                 1   15826    5589\n",
       "21                 1   21415    7544\n",
       "24                 1   28959    4855\n",
       "27                 1   33814    2921"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_offsets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "22cbf684430221207eaef06a43a2d226d1d08371",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_offsets_df.to_csv(\"test_offsets.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d6c29a5d75ac478a33c7d8a90dd3d6b4f0eb5333"
   },
   "source": [
    "## Create a random train/validation split\n",
    "\n",
    "We split on products, not on individual images. Since some of the categories only have a few products, we do the split separately for each category.\n",
    "\n",
    "This creates two new tables, one for the training images and one for the validation images. There is a row for every single image, so if a product has more than one image it occurs more than once in the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "c58f459cf2e5e8fa19654439cbea34b989193c29",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_val_set(df, split_percentage=0.2, drop_percentage=0.):\n",
    "    # Find the product_ids for each category.\n",
    "    category_dict = defaultdict(list)\n",
    "    for ir in tqdm(df.itertuples()):\n",
    "        category_dict[ir[4]].append(ir[0])\n",
    "\n",
    "    train_list = []\n",
    "    val_list = []\n",
    "    with tqdm(total=len(df)) as pbar:\n",
    "        for category_id, product_ids in category_dict.items():\n",
    "            category_idx = cat2idx[category_id]\n",
    "\n",
    "            # Randomly remove products to make the dataset smaller.\n",
    "            keep_size = int(len(product_ids) * (1. - drop_percentage))\n",
    "            if keep_size < len(product_ids):\n",
    "                product_ids = np.random.choice(product_ids, keep_size, replace=False)\n",
    "\n",
    "            # Randomly choose the products that become part of the validation set.\n",
    "            val_size = int(len(product_ids) * split_percentage)\n",
    "            if val_size > 0:\n",
    "                val_ids = np.random.choice(product_ids, val_size, replace=False)\n",
    "            else:\n",
    "                val_ids = []\n",
    "\n",
    "            # Create a new row for each image.\n",
    "            for product_id in product_ids:\n",
    "                row = [product_id, category_idx]\n",
    "                for img_idx in range(df.loc[product_id, \"num_imgs\"]):\n",
    "                    if product_id in val_ids:\n",
    "                        val_list.append(row + [img_idx])\n",
    "                    else:\n",
    "                        train_list.append(row + [img_idx])\n",
    "                pbar.update()\n",
    "                \n",
    "    columns = [\"product_id\", \"category_idx\", \"img_idx\"]\n",
    "    train_df = pd.DataFrame(train_list, columns=columns)\n",
    "    val_df = pd.DataFrame(val_list, columns=columns)   \n",
    "    return train_df, val_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "52fa382d788a53b761f76da8f3cd7f12cde3f2de"
   },
   "source": [
    "Create a 80/20 split. Also drop 90% of all products to make the dataset more manageable. (Note: if `drop_percentage` > 0, the progress bar doesn't go all the way.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "57bbe07de76a55d96cdb6f5ee81f959137518bcc",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7069896it [00:10, 649651.12it/s]\n",
      " 10%|▉         | 704102/7069896 [00:19<02:58, 35701.83it/s]\n"
     ]
    }
   ],
   "source": [
    "train_images_df, val_images_df = make_val_set(train_offsets_df, split_percentage=0.2, \n",
    "                                              drop_percentage=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "fb14359468e84e5cf12c528c3fc4864b1b036212",
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>category_idx</th>\n",
       "      <th>img_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12683221</td>\n",
       "      <td>5055</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27222</td>\n",
       "      <td>5055</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10245493</td>\n",
       "      <td>5055</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11527892</td>\n",
       "      <td>5055</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9793349</td>\n",
       "      <td>5055</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id  category_idx  img_idx\n",
       "0    12683221          5055        0\n",
       "1       27222          5055        0\n",
       "2    10245493          5055        0\n",
       "3    11527892          5055        0\n",
       "4     9793349          5055        0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "4999f912de700606747fb45ea6b8376732aa7053",
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>category_idx</th>\n",
       "      <th>img_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7422247</td>\n",
       "      <td>5055</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12057481</td>\n",
       "      <td>5055</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22370</td>\n",
       "      <td>5055</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14339587</td>\n",
       "      <td>5055</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23003232</td>\n",
       "      <td>5055</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id  category_idx  img_idx\n",
       "0     7422247          5055        0\n",
       "1    12057481          5055        0\n",
       "2       22370          5055        0\n",
       "3    14339587          5055        0\n",
       "4    23003232          5055        0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_images_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "4c770fde3d66ea2dead39c315ead9ef888647dc7",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training images: 988243\n",
      "Number of validation images: 242797\n",
      "Total images: 1231040\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of training images:\", len(train_images_df))\n",
    "print(\"Number of validation images:\", len(val_images_df))\n",
    "print(\"Total images:\", len(train_images_df) + len(val_images_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "335ef769fbe3d19607082c20c6e4ed87aaf75dd6"
   },
   "source": [
    "Are all categories represented in the train/val split? (Note: if the drop percentage is high, then very small categories won't have enough products left to make it into the validation set.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "63d2c8ad27a4229e64ab8ab5cc7528225e41ac2f",
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5270, 4268)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_images_df[\"category_idx\"].unique()), len(val_images_df[\"category_idx\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "46f9c634153d6f162e0ec6297106d2c34ed00ce2"
   },
   "source": [
    "Quickly verify that the split really is approximately 80-20:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "9cdf009a8fe3301265af0f085f1f6108180e4d9d",
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25966850828729282"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_idx = 619\n",
    "num_train = np.sum(train_images_df[\"category_idx\"] == category_idx)\n",
    "num_val = np.sum(val_images_df[\"category_idx\"] == category_idx)\n",
    "num_val / num_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6968b921d001e81eac33ffa947844670c551700e"
   },
   "source": [
    "Close enough. ;-) Remember that we split on products but not all products have the same number of images, which is where the slightly discrepancy comes from. (Also, there tend to be fewer validation images if `drop_percentage` > 0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "61e4d715f9ad51abfe9fc6df1ae2748f440c2546"
   },
   "source": [
    "Save the lookup tables as CSV so that we don't need to repeat the above procedure again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "6ac5f429dbaa69dc6e8e978cc647e373afe24257",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_images_df.to_csv(\"train_images.csv\")\n",
    "val_images_df.to_csv(\"val_images.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7eb76e8bd1c331cb214100dc084755c5695eb839"
   },
   "source": [
    "## Lookup table for test set images\n",
    "\n",
    "Create a list containing a row for each image. If a product has more than one image, it appears more than once in this list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_uuid": "6db0fa98034483165655862276d39ef6b974ac7b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_test_set(df):\n",
    "    test_list = []\n",
    "    for ir in tqdm(df.itertuples()):\n",
    "        product_id = ir[0]\n",
    "        num_imgs = ir[1]\n",
    "        for img_idx in range(num_imgs):\n",
    "            test_list.append([product_id, img_idx])\n",
    "\n",
    "    columns = [\"product_id\", \"img_idx\"]\n",
    "    test_df = pd.DataFrame(test_list, columns=columns)\n",
    "    return test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_uuid": "e725d27a0feea6db9b070b09ceebc4c8efbf09d7",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1768182it [00:04, 372740.41it/s]\n"
     ]
    }
   ],
   "source": [
    "test_images_df = make_test_set(test_offsets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_uuid": "c478607cf4e80ddbe111312e7874cbda5a3dae00",
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>img_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id  img_idx\n",
       "0          10        0\n",
       "1          10        1\n",
       "2          10        2\n",
       "3          14        0\n",
       "4          21        0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_uuid": "10148a7d4104e7d3750196aaaf462c84d14cf311",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test images: 3095080\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of test images:\", len(test_images_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_uuid": "38c3edbe9611e70901eb0c4d8a91c9e64f2ff625",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_images_df.to_csv(\"test_images.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0e6fea1f1ae641892cca49d8d7fa6c9a80a78b50"
   },
   "source": [
    "# The generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a715958a3d274bd9de05ea1450dde0c0354f338b"
   },
   "source": [
    "First load the lookup tables from the CSV files (you don't need to do this if you just did all the steps from part 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0033d7f51940158b306faf3ae9dd1b40da62f4d1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categories_df = pd.read_csv(\"categories.csv\", index_col=0)\n",
    "cat2idx, idx2cat = make_category_tables()\n",
    "\n",
    "train_offsets_df = pd.read_csv(\"train_offsets.csv\", index_col=0)\n",
    "train_images_df = pd.read_csv(\"train_images.csv\", index_col=0)\n",
    "val_images_df = pd.read_csv(\"val_images.csv\", index_col=0)\n",
    "\n",
    "test_offsets_df = pd.read_csv(\"test_offsets.csv\", index_col=0)\n",
    "test_images_df = pd.read_csv(\"test_images.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2abaace6f491875d47b500b58a6cac4098911356"
   },
   "source": [
    "The Keras generator is implemented by the `BSONIterator` class. It creates batches of images (and their one-hot encoded labels) directly from the BSON file. It can be used with multiple workers.\n",
    "\n",
    "**Note:** For fastest results, put the train.bson and test.bson files on a fast drive (SSD).\n",
    "\n",
    "See also the code in: https://github.com/fchollet/keras/blob/master/keras/preprocessing/image.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_uuid": "62e8153093231301eeaaf64ead08c4858ace0e80",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import Iterator\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "\n",
    "class BSONIterator(Iterator):\n",
    "    def __init__(self, bson_file, images_df, offsets_df, num_class,\n",
    "                 image_data_generator, target_size=(180, 180), with_labels=True,\n",
    "                 batch_size=32, shuffle=False, seed=None):\n",
    "\n",
    "        self.file = bson_file\n",
    "        self.images_df = images_df\n",
    "        self.offsets_df = offsets_df\n",
    "        self.with_labels = with_labels\n",
    "        self.samples = len(images_df)\n",
    "        self.num_class = num_class\n",
    "        self.image_data_generator = image_data_generator\n",
    "        self.target_size = tuple(target_size)\n",
    "        self.image_shape = self.target_size + (3,)\n",
    "\n",
    "        print(\"Found %d images belonging to %d classes.\" % (self.samples, self.num_class))\n",
    "\n",
    "        super(BSONIterator, self).__init__(self.samples, batch_size, shuffle, seed)\n",
    "\n",
    "    def _get_batches_of_transformed_samples(self, index_array):\n",
    "        batch_x = np.zeros((len(index_array),) + self.image_shape, dtype=K.floatx())\n",
    "        if self.with_labels:\n",
    "            batch_y = np.zeros((len(batch_x), self.num_class), dtype=K.floatx())\n",
    "\n",
    "        for i, j in enumerate(index_array):\n",
    "            # Protect file and dataframe access with a lock.\n",
    "            with self.lock:\n",
    "                image_row = self.images_df.iloc[j]\n",
    "                product_id = image_row[\"product_id\"]\n",
    "                offset_row = self.offsets_df.loc[product_id]\n",
    "\n",
    "                # Read this product's data from the BSON file.\n",
    "                self.file.seek(offset_row[\"offset\"])\n",
    "                item_data = self.file.read(offset_row[\"length\"])\n",
    "\n",
    "            # Grab the image from the product.\n",
    "            item = bson.BSON.decode(item_data)\n",
    "            img_idx = image_row[\"img_idx\"]\n",
    "            bson_img = item[\"imgs\"][img_idx][\"picture\"]\n",
    "\n",
    "            # Preprocess the image.\n",
    "            img = load_img(io.BytesIO(bson_img), target_size=self.target_size)\n",
    "            x = img_to_array(img)\n",
    "            x = self.image_data_generator.random_transform(x)\n",
    "            x = self.image_data_generator.standardize(x)\n",
    "\n",
    "            # Add the image and the label to the batch (one-hot encoded).\n",
    "            batch_x[i] = x\n",
    "            if self.with_labels:\n",
    "                batch_y[i, image_row[\"category_idx\"]] = 1\n",
    "\n",
    "        if self.with_labels:\n",
    "            return batch_x, batch_y\n",
    "        else:\n",
    "            return batch_x\n",
    "\n",
    "    def next(self):\n",
    "        with self.lock:\n",
    "            index_array = next(self.index_generator)\n",
    "        return self._get_batches_of_transformed_samples(index_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_uuid": "a98628e6b09dd0a2a011e9f80c13240d00c34f39",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_bson_file = open(train_bson_path, \"rb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b880311c89a4527a30278c351d347d0b49922b0b"
   },
   "source": [
    "Create a generator for training and a generator for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_uuid": "3c2e7eac68de77edc404a1e4db460201361699e8",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 988243 images belonging to 5270 classes.\n",
      "Found 242797 images belonging to 5270 classes.\n"
     ]
    }
   ],
   "source": [
    "num_classes = 5270\n",
    "num_train_images = len(train_images_df)\n",
    "num_val_images = len(val_images_df)\n",
    "batch_size = 128\n",
    "\n",
    "# Tip: use ImageDataGenerator for data augmentation and preprocessing.\n",
    "train_datagen = ImageDataGenerator()\n",
    "train_gen = BSONIterator(train_bson_file, train_images_df, train_offsets_df, \n",
    "                         num_classes, train_datagen, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_datagen = ImageDataGenerator()\n",
    "val_gen = BSONIterator(train_bson_file, val_images_df, train_offsets_df,\n",
    "                       num_classes, val_datagen, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "913b8737309312041a5e36e163f8dae1647419d0"
   },
   "source": [
    "How fast is the generator? Create a single batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_uuid": "1d870ed39313c825bd9b9b7a767418b5c6e1ee02",
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Series' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-872245b1f6e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# warm-up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time bx, by = next(train_gen)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py36/lib/python3.6/site-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-e51128093b41>\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mindex_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-32-e51128093b41>\u001b[0m in \u001b[0;36m_get_batches_of_transformed_samples\u001b[0;34m(self, index_array)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0;31m# Read this product's data from the BSON file.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffset_row\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"offset\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m                 \u001b[0mitem_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffset_row\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"length\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Series' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "next(train_gen)  # warm-up\n",
    "\n",
    "%time bx, by = next(train_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "20827722c85a340949d56fd7e5aaf60290d8819b"
   },
   "source": [
    "Does it really output images and one-hot encoded class labels? Note that the images are pre-processed (and augmented) and therefore may look weird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "_uuid": "322b605b936cd9e6958dac73afa425f4c238593e",
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-8b7d2412b5f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'bx' is not defined"
     ]
    }
   ],
   "source": [
    "plt.imshow(bx[-1].astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f394b6c3413b7a81aff31bd7d613ec56c86c60a4",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_idx = np.argmax(by[-1])\n",
    "cat_id = idx2cat[cat_idx]\n",
    "categories_df.loc[cat_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3c31f92aae6be5cdb3a676c8ad0e4730970529fc",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%time bx, by = next(val_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "da1588e099334dda9d64c54101bf03501618051b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(bx[-1].astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "640b667dc53205208f0b92282df8aa488e41f126",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_idx = np.argmax(by[-1])\n",
    "cat_id = idx2cat[cat_idx]\n",
    "categories_df.loc[cat_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fe732597b95a21b3b87b7213c2a7064271e7b917"
   },
   "source": [
    "# Part 3: Training\n",
    "\n",
    "Create a very simple Keras model and train it, to test that the generators work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4de26d347b65ce99c681107fc0d0bfb28fe8a69e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D, GlobalAveragePooling2D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, 3, padding=\"same\", activation=\"relu\", input_shape=(180, 180, 3)))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(64, 3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(128, 3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(num_classes, activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "_uuid": "2e3c6153a6672de786601aab81b2de379caaa4a9",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To train the model:\n",
    "model.fit_generator(train_gen,\n",
    "                    steps_per_epoch = num_train_images // batch_size,\n",
    "                    epochs = 1,\n",
    "                    validation_data = val_gen,\n",
    "                    validation_steps = num_val_images // batch_size,\n",
    "                    workers = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0db0fb638d042ff8dc6c2e6ba42403f17d94490c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To evaluate on the validation set:\n",
    "model.evaluate_generator(val_gen, steps=num_val_images // batch_size, workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9b4f16dad42f3eeaa5d066cdf17cc99e8e36a963"
   },
   "source": [
    "# Part 4: Test set predictions\n",
    "\n",
    "Use `BSONIterator` to load the test set images in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e57f12e08024efe607337bc8d5f04688b3e721d8",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_bson_file = open(test_bson_path, \"rb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a5a436b9a3c318cff32e08451c3e39a65b48188d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator()\n",
    "test_gen = BSONIterator(test_bson_file, test_images_df, test_offsets_df,\n",
    "                        num_classes, test_datagen, batch_size=batch_size, \n",
    "                        with_labels=False, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "08f2b04d2ff29adf8231ec3096988e1345352e29"
   },
   "source": [
    "Running `model.predict_generator()` gives a list of 3095080 predictions, one for each image. \n",
    "\n",
    "The indices of the predictions correspond to the indices in `test_images_df`. After making the predictions, you probably want to average the predictions for products that have multiple images.\n",
    "\n",
    "Use `idx2cat[]` to convert the predicted category index back to the original class label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "_uuid": "489126bc36b971bc86af21f3cfda8ae23cba5c1b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_test_samples = len(test_images_df)\n",
    "predictions = model.predict_generator(test_gen, steps=num_test_samples // batch_size, workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "59e28854d5477ff2e065f2ed7fe4fd6003402632",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
